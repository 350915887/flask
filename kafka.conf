# 定义 agent 的各个组件
a1.sources = r1
a1.channels = c1
a1.sinks = k1

# Source 配置
# 使用 Spooling Directory Source 监视一个目录
a1.sources.r1.type = spooldir
# 指定 Flume 监视的目录路径，Flume 将处理该目录下的所有新文件
a1.sources.r1.spoolDir = D:\project\fault-diagnosis\FlumeData
# 是否在 header 中添加文件名，这样每个事件都会包含其来源文件的名字
a1.sources.r1.fileHeader = true
# 设置 header 中文件名的键值
a1.sources.r1.basenameHeaderKey = file
# 文件处理完毕后的删除策略，immediate 表示立即删除
a1.sources.r1.deletePolicy = immediate
# 忽略的文件模式，这里配置为忽略临时文件，如后缀为 .tmp 或 .TMP
a1.sources.r1.ignorePattern = ^(.)*\.(tmp|TMP)$
# Flume 用于记录已处理文件的位置信息的目录
a1.sources.r1.trackerDir = .flumespool
# 设置数据反序列化方式，LINE 表示按行读取
a1.sources.r1.deserializer = LINE

# Channel 配置
# 使用内存 channel，这是一种基于内存的事件存储机制
a1.channels.c1.type = memory
# channel 的容量，即 channel 中可以存储的最大事件数
a1.channels.c1.capacity = 1000
# 每个事务最大处理的事件数
a1.channels.c1.transactionCapacity = 100

# Sink 配置
# 使用 Kafka Sink 将数据发送到 Kafka
a1.sinks.k1.type = org.apache.flume.sink.kafka.KafkaSink
# 指定 Kafka 服务器的地址和端口
a1.sinks.k1.kafka.bootstrap.servers = localhost:9092
# 指定 Kafka 主题名称，数据将被发送到这个主题
a1.sinks.k1.kafka.topic = fault_diagnosis_topic
# 设置每次发送到 Kafka 的批次大小
a1.sinks.k1.kafka.flumeBatchSize = 20
# Kafka 生产者确认策略，1 表示 leader 接收到数据后就会返回确认
a1.sinks.k1.kafka.producer.acks = 1
# 设置 Kafka 生产者的消息发送延迟，以毫秒计，用于批处理优化
a1.sinks.k1.kafka.producer.linger.ms = 1
# 设置 Kafka 生产者的数据压缩类型
a1.sinks.k1.kafka.producer.compression.type = snappy

# 链接 source, sink 和 channel
a1.sources.r1.channels = c1
a1.sinks.k1.channel = c1



"""
启动 Flume Agent 的步骤
确保 Kafka 正在运行，并且已经创建了名为 fault_diagnosis_topic 的主题。
将上述配置保存到一个文件中，比如命名为 flume.conf。
使用以下命令启动 Flume agent：
flume-ng agent --conf --conf C:\flume\conf --conf-file C:\flume\conf\kafka.conf --name a1 -Dflume.root.logger=INFO,console
--conf:
这个参数指定了 Flume 配置文件的目录。这个目录应该包含 Flume 所需的所有配置文件，如 flume-env.sh，它可以包含环境变量和JVM设置。
示例中的 /path/to/flume/conf 应该被替换为实际的 Flume 配置文件夹路径。
--conf-file:
这个参数指定了具体的 Flume 配置文件的路径。这个文件描述了 Flume agent 的结构，包括 sources、channels 和 sinks 的配置。
示例中的 /path/to/flume.conf 应该被替换为实际的 Flume 配置文件路径。
--name:
这个参数指定了要启动的 Flume agent 的名称，这个名称应该与配置文件中定义的 agent 名称一致。
在此例中，a1 是配置文件中定义的 agent 名称。
这个配置将持续监视指定的目录，任何新添加到该目录中的文本文件将被读取，并且文件内容将作为事件发送到 Kafka。文件处理完毕后将被删除，以避免重复处理。
"""